{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 1: Classification and Vector Spaces\n",
    "# Own project 1: Classifying positivity on my own tweets\n",
    "\n",
    "In this notebook I will apply the knowledge I gained from the previous notebooks to classify tweets as positive or negative on my own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tweepy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own tweets\n",
    "These tweets will be the data where I will make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = \"fcx_xm\"\n",
    "\n",
    "with open(\"twitter-api-keys.local.json\") as f:\n",
    "    keys = json.load(f)\n",
    "    api_key = keys[\"api_key\"]\n",
    "    api_key_secret = keys[\"api_key_secret\"]\n",
    "    access_token = keys[\"access_token\"]\n",
    "    access_token_secret = keys[\"access_token_secret\"]\n",
    "    bearer_token = keys[\"bearer_token\"]\n",
    "\n",
    "# Get my latest 200 tweets\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "tweets = api.user_timeline(screen_name=me, count=200, tweet_mode=\"extended\", include_rts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23452165acaf481cbfad33403c8260be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If tweets.pkl exists, load it. Otherwise, save the tweets to tweets.pkl\n",
    "if os.path.exists(\"tweets.pkl\"):\n",
    "    with open(\"tweets.pkl\", \"rb\") as f:\n",
    "        tweets = pickle.load(f)\n",
    "else:\n",
    "    limit = 20000\n",
    "    tweet_cursor = tweepy.Cursor(api.user_timeline, screen_name=me, count=200, tweet_mode=\"extended\", include_rts=False).items(limit)\n",
    "    tweets = []\n",
    "    for tweet in tqdm(tweet_cursor):\n",
    "        tweets.append(tweet)\n",
    "    with open(\"tweets.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2174\n",
      "https://t.co/ABinyaONLl\n",
      "\n",
      "\n",
      "https://t.co/ZmlKKfHmhT\n",
      "\n",
      "\n",
      "me estan dejando de encajar los pi√±os qiza es hora de ponerse el retenedor dsps de mmm nose 5 meses\n",
      "\n",
      "\n",
      "qe te calles 7 veces pollasucia https://t.co/T9x5JDNAmi\n",
      "\n",
      "\n",
      "tengo q ir a renovar el dnie plan de viernes tarde üò≥üòã\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Type, len\n",
    "print(type(tweets))\n",
    "print(len(tweets))\n",
    "\n",
    "# Print 5 random tweets\n",
    "for tweet in np.random.choice(tweets, 5):\n",
    "    print(tweet.full_text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data\n",
    "\n",
    "A IMDB dataset will be used to train the model. It contains reviews of movies and their sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB_clean.csv\n",
    "imdb_df = pd.read_csv(\"IMDB_clean.csv\")\n",
    "# In review_es, transform \"positivo\" to 1 and \"negativo\" to 0 in column sentimiento\n",
    "imdb_df[\"sentimiento\"] = imdb_df[\"sentimiento\"].replace({\"positivo\": 1, \"negativo\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uno de los otros cr√≠ticos ha mencionado que de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Una peque√±a peque√±a producci√≥n.La t√©cnica de f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pens√© que esta era una manera maravillosa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B√°sicamente, hay una familia donde un ni√±o peq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_es  sentimiento\n",
       "0  Uno de los otros cr√≠ticos ha mencionado que de...            1\n",
       "1  Una peque√±a peque√±a producci√≥n.La t√©cnica de f...            1\n",
       "2  Pens√© que esta era una manera maravillosa de p...            1\n",
       "3  B√°sicamente, hay una familia donde un ni√±o peq...            0\n",
       "4  El \"amor en el tiempo\" de Petter Mattei es una...            1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two lists of reviews and their labels\n",
    "reviews = imdb_df[\"review_es\"].tolist()\n",
    "labels = imdb_df[\"sentimiento\"].tolist()\n",
    "\n",
    "# Split into train and test. X is reviews, y is labels\n",
    "train_x = reviews[:int(len(reviews) * 0.8)]\n",
    "train_y = labels[:int(len(labels) * 0.8)]\n",
    "test_x = reviews[int(len(reviews) * 0.8):]\n",
    "test_y = labels[int(len(labels) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set:\n",
      "40000\n",
      "40000\n",
      "\n",
      "Test set:\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain set:\")\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(\"\\nTest set:\")\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process review function\n",
    "\n",
    "def process_review(review):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - A string containing a review\n",
    "    Output:\n",
    "        - A list of words containing the processed review\n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = nltk.SnowballStemmer(\"spanish\")\n",
    "    stopwords_es = stopwords.words(\"spanish\")\n",
    "    # Remove accents from stopwords and remove duplicates\n",
    "    stopwords_es = [unidecode.unidecode(w) for w in stopwords_es]\n",
    "    stopwords_es = list(set(stopwords_es))\n",
    "    # Clean\n",
    "    review = re.sub(r'^RT[\\s]+', '', review)\n",
    "    review = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', review)\n",
    "    review = re.sub(r'#', '', review)\n",
    "    review = review.lower()\n",
    "    review = review.strip()\n",
    "    review = unidecode.unidecode(review) #remove accents\n",
    "    \n",
    "    # Tokenize\n",
    "    review_tokens = nltk.word_tokenize(review, \"spanish\")\n",
    "\n",
    "    # Remove symbols\n",
    "    review_tokens = [token for token in review_tokens if token.isalpha()]\n",
    "\n",
    "    # Token, stem, remove stopwords\n",
    "    reviews_clean = []\n",
    "\n",
    "    for token in review_tokens:\n",
    "        if token not in stopwords_es:\n",
    "            reviews_clean.append(stemmer.stem(token))\n",
    "\n",
    "    return reviews_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random 5 reviews:\n",
      "['legendari', 'productor', 'pelicul', 'walt', 'disney', 'traj', 'tres', 'mejor', 'cuent', 'had', 'mund', 'pantall', 'permanec', 'pelicul', 'anim', 'popular', 'tiemp', 'primer', 'innov', 'clasic', 'blancaniev', 'niev', 'siet', 'enanit', 'lanz', 'ultim', 'entonc', 'baj', 'apreci', 'bell', 'durmient', 'hiz', 'debut', 'dos', 'quiz', 'adaptacion', 'satisfactori', 'clasic', 'cuent', 'had', 'cinderell', 'tres', 'pelicul', 'cinderell', 'fiel', 'origen', 'iron', 'diferent', 'blancaniev', 'bien', 'mal', 'convirti', 'much', 'version', 'definit', 'histori', 'cinderell', 'sigui', 'mism', 'camin', 'aunqu', 'exit', 'blancaniev', 'respons', 'restaur', 'donador', 'disney', 'fortun', 'nunc', 'logr', 'mism', 'reconoc', 'audienci', 'ciert', 'mereci', 'disney', 'vez', 'orgull', 'eligi', 'manipul', 'clasic', 'cambi', 'elabor', 'agreg', 'sustanci', 'histori', 'lug', 'reescrib', 'pantall', 'result', 'encant', 'combinacion', 'excelent', 'animacion', 'tecnic', 'bell', 'suav', 'talent', 'voz', 'perfect', 'llev', 'histori', 'vid', 'resplandor', 'perdur', 'dia', 'hoy', 'ilen', 'woods', 'interpret', 'radi', 'grab', 'disc', 'demostracion', 'cancion', 'favor', 'autor', 'material', 'hoffm', 'mack', 'dav', 'jerry', 'livingston', 'disney', 'escuch', 'sabi', 'encontr', 'cenicient', 'hech', 'interpret', 'sincer', 'woods', 'suen', 'dese', 'corazon', 'hac', 'asi', 'amor', 'oh', 'sing', 'sweet', 'nightingal', 'perfect', 'eleanor', 'audley', 'iri', 'voz', 'maleficient', 'bell', 'durmient', 'captur', 'magistral', 'crueld', 'hel', 'madrastr', 'mientr', 'rhod', 'williams', 'lucill', 'bliss', 'conden', 'maner', 'convincent', 'luis', 'van', 'root', 'realiz', 'maner', 'admir', 'rey', 'gran', 'duqu', 'jam', 'macdonald', 'entran', 'jaq', 'gus', 'raton', 'devot', 'cinderell', 'william', 'phipps', 'dialog', 'princip', 'futur', 'talk', 'show', 'anfitrion', 'mik', 'dougl', 'proporcion', 'voz', 'cant', 'veteran', 'pelicul', 'disney', 'naci', 'vern', 'felton', 'jug', 'madrug', 'had', 'hiz', 'mejor', 'numer', 'propi', 'artist', 'respons', 'mir', 'pelicul', 'mary', 'bla', 'cuy', 'uso', 'inspir', 'color', 'admir', 'gran', 'med', 'disney', 'eleg', 'fond', 'epoc', 'frances', 'agreg', 'tremend', 'calid', 'pelicul', 'import', 'personaj', 'creibl', 'cinderell', 'lucif', 'gat', 'delici', 'malv', 'madrastr', 'tra', 'tod', 'vid', 'vital', 'histori', 'menud', 'cont', 'dificil', 'cre', 'pelicul', 'anim', 'relacion', 'aniversari', 'pelicul', 'tan', 'coincidental', 'proxim', 'tempor', 'vacacion', 'cinderell', 'acab', 'ser', 'lanz', 'edicion', 'especial', 'dvd', 'simplement', 'nunc', 'vist', 'mejor', 'pelicul', 'complet', 'restaur', 'deb', 'ser', 'vistos', 'ser', 'apreci', 'bast', 'dec', 've', 'maravill', 'agreg', 'band', 'sonor', 'estere', 'mejor', 'sirv', 'bien', 'music', 'extras', 'dvd', 'ahor', 'part', 'estand', 'edicion', 'disney', 'platinum', 'demasi', 'numer', 'list', 'aqui', 'costumbr', 'dirig', 'nin', 'inclin', 'adult', 'rest', 'caen', 'algun', 'lug', 'fanat', 'real', 'querr', 'obten', 'conjunt', 'regal', 'luj', 'junt', 'celd', 'real', 'pelicul', 'ocho', 'bocet', 'caracter', 'inclu', 'libr', 'tap', 'dur', 'pagin', 'sol', 'incorpor', 'mayor', 'part', 'material', 'encuentr', 'libr', 'special', 'edition', 'hom', 'vide', 'lanzamient', 'costumbr', 'disney', 'cinderell', 'sol', 'dispon', 'tiemp', 'limit', 'entonc', 'gust', 'amant', 'cenicient', 'consigal', 'ahor', 'edicion', 'verdader', 'suen', 'hech', 'realid']\n",
      "\n",
      "['funcion', 'mejor', 'hech', 'mitchell', 'malt', 'men', 'entonc', 'escatim', 'vist', 'joe', 'don', 'bak', 'corr', 'alrededor', 'revest', 'local', 'mediterrane', 'escen', 'traj', 'vaquer', 'aspect', 'ridicul', 'mencion', 'actu', 'viej', 'pistoler', 'siend', 'mitchell', 'pelicul', 'sufr', 'falt', 'brutal', 'polici', 'men', 'comentari', 'comical', 'mik', 'bots', 'hic', 'tarif', 'agrad', 'episodi', 'embarg', 'pued', 'imagin', 'verl', 'mism']\n",
      "\n",
      "['aquell', 'espect', 'pens', 'pelicul', 'ali', 'primer', 'represent', 'mach', 'mariquit', 'impregn', 'extraterrestr', 'malevol', 'noch', 'besti', 'sangr', 'hiz', 'anos', 'pued', 'ven', 'sorpres', 'pelicul', 'prim', 'hombr', 'amer', 'espaci', 'crashlands', 'vuelv', 'tierr', 'despu', 'exam', 'cre', 'muert', 'tard', 'vuelv', 'volv', 'caer', 'sol', 'medi', 'docen', 'cos', 'alienigen', 'marhor', 'alienigen', 'crec', 'abdom', 'mam', 'ali', 'aparec', 'aterroriz', 'pequen', 'band', 'cientif', 'observ', 'hero', 'gravid', 'parec', 'parec', 'ten', 'cuerp', 'oso', 'cabez', 'yarnek', 'criatur', 'roc', 'estrell', 'trek', 'episodi', 'mod', 'tiemp', 'cort', 'minut', 'grup', 'pequen', 'cientif', 'monstru', 'aspect', 'barat', 'pelicul', 'sugier', 'men', 'calent', 'grad', 'z', 'limit', 'extern', 'estrenari', 'cuatr', 'anos', 'despu', 'bien', 'escrib', 'espectacul', 'general', 'jact', 'pes', 'titul', 'ludic', 'pelicul', 'decidid', 'cifr', 'horror', 'ofrec', 'mied', 'laffs', 'suspens', 'poc', 'com', 'pensamient', 'posterior', 'parec', 'cuest', 'alrededor', 'hac', 'probabl', 'cost', 'dobl', 'puntaj', 'musical', 'menud', 'parec', 'ten', 'relacion', 'acontec', 'usar', 'palabr', 'accion', 'pantall', 'final', 'pelicul', 'much', 'pregunt', 'sig', 'siend', 'hero', 'dar', 'luz', 'criatur', 'alienigen', 'necesit', 'decapit', 'person', 'aprend', 'idiom', 'justific', 'titul', 'dud', 'extraterrestr', 'viaj', 'espaci', 'pued', 'aterriz', 'planet', 'lug', 'necesit', 'pase', 'barc', 'impregn', 'hero', 'empez', 'asunt', 'pequen', 'barat', 'pued', 'ser', 'molest', 'realment', 'sol', 'complet', 'sol']\n",
      "\n",
      "['pelicul', 'largometr', 'cgi', 'acab', 'ser', 'lanz', 'ano', 'bien', 'brind', 'entreten', 'nin', 'fanat', 'alvin', 'seguidor', 'crec', 'version', 'anos', 'espectacul', 'dibuj', 'anim', 'probabl', 'aventur', 'chipmunk', 'mejor', 'alvin', 'pelicul', 'anim', 'bas', 'licrist', 'siempr', 'empez', 'animacion', 'tan', 'terribl', 'disen', 'personaj', 'deb', 'cartuch', 'diferent', 'pelicul', 'pelicul', 'movimient', 'sol', 'divert', 'ver', 'voc', 'celeb', 'efect', 'gener', 'cgi', 'sol', 'calid', 'pur', 'animacion', 'dibuj', 'man', 'color', 'fantast', 'brillant', 'audac', 'hermos', 'chist', 'humor', 'estand', 'tipic', 'ardill', 'narrat', 'lug', 'verd', 'aventur', 'chipmunk', 'pelicul', 'accion', 'viv', 'deberi', 'hab', 'sid', 'alvin', 'simon', 'theodor', 'compit', 'chipett', 'elenor', 'jeanett', 'britney', 'concurs', 'glob', 'air', 'calient', 'camin', 'nin', 'encuentr', 'tip', 'problem', 'dilem', 'resolv', 'maner', 'ningun', 'pelicul', 'chipmunk', 'complet', 'rendicion', 'extran', 'roc', 'clasic', 'himn', 'pop', 'aventur', 'ardill', 'nin', 'adult', 'igual', 'ventaj', 'pelicul', 'cgi', 'mientr', 'version', 'obtendr', 'admir', 'pelicul', 'atraer', 'fanat', 'ligmunk', 'joven', 'mayor', 'bagdarasi', 'karm', 'proporcion', 'voc', 'heli', 'tri', 'pelicul', 'tod', 'pelicul', 'visit', 'oblig', 'fanat', 'caricatur', 'muestr', 'mism', 'dej', 'decepcion', 'vist', 'version', 'accion', 'viv', 'sentir', 'pelicul', 'esfuerz', 'mejor', 'contr', 'hech', 'deberi', 'ir', 'verl', 'todavi', 'inclus', 'aun', 'asi', 'olvid', 'pelicul', 'jason', 'lee', 'altern', 'quedat']\n",
      "\n",
      "['sporting', 'titul', 'aparent', 'adecu', 'destac', 'looney', 'tun', 'grisly', 'giall', 'tortur', 'patit', 'embarg', 'thrill', 'grad', 'horror', 'maestr', 'luci', 'fulci', 'algui', 'estrangul', 'nin', 'preadolescent', 'puebl', 'rural', 'suren', 'italian', 'tipic', 'gialli', 'sospech', 'barb', 'bouchet', 'patrizi', 'luc', 'escrit', 'vist', 'chic', 'ric', 'escond', 'despu', 'escandal', 'drog', 'florind', 'bolk', 'marti', 'muj', 'vudu', 'epilept', 'local', 'brujeri', 'practic', 'beau', 'giusepp', 'idiot', 'local', 'sacerdot', 'car', 'dulc', 'madr', 'madr', 'asi', 'suces', 'pelicul', 'present', 'piez', 'conjunt', 'inusual', 'violent', 'inclu', 'bat', 'caden', 'personaj', 'principal', 'cementeri', 'secuenci', 'realist', 'vist', 'ingeni', 'duquen', 'asesin', 'final', 'revel', 'estall', 'violenci', 'pelicul', 'compens', 'hech', 'verdader', 'asust', 'suspens', 'habl', 'aun', 'asi', 'gall', 'fascin', 'inusual', 'telon', 'fond', 'rural', 'asesinat', 'infantil', 'personaj', 'extran', 'caracter', 'extran', 'puntaj', 'freaky', 'riz', 'ortolani', 'pelicul', 'sid', 'bell', 'fotografi', 'supong', 'ser', 'mont', 'cerc', 'adriat', 'sur', 'itali', 'men', 'fuerz', 'policial', 'ciud', 'agradec', 'credit', 'cierr', 'mientr', 'subtitul', 'hech', 'trabaj', 'dvd', 'aspect', 'fin', 'aun', 'mejor', 'jerg', 'estadounidens', 'convenc', 'entorn', 'italian', 'rural', 'deb', 'agradec', 'anchor', 'bay', 'trabaj', 'bien', 'hech', 'oh', 'titul', 'perfect']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean 5 random reviews\n",
    "print(\"\\nRandom 5 reviews:\")\n",
    "for review in np.random.choice(train_x, 5):\n",
    "    print(process_review(review))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build freqs function\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in tqdm(zip(yslist, tweets), total=len(tweets)):\n",
    "        for word in process_review(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check with pickle if freqs.pkl exists. If not calculate freqs and save\n",
    "if os.path.exists(\"freqs.pkl\"):\n",
    "    with open(\"freqs.pkl\", \"rb\") as f:\n",
    "        freqs = pickle.load(f)\n",
    "else:\n",
    "    freqs = build_freqs(train_x, train_y)\n",
    "    with open(\"freqs.pkl\", \"wb\") as f:\n",
    "        pickle.dump(freqs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Freqs:\n",
      "127763\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Print len and type\n",
    "print(\"\\nFreqs:\")\n",
    "print(len(freqs))\n",
    "print(type(freqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sigmoid of 0:\n",
      "0.5\n",
      "\n",
      "Sigmoid of 1:\n",
      "0.7310585786300049\n"
     ]
    }
   ],
   "source": [
    "# Test it\n",
    "print(\"\\nSigmoid of 0:\")\n",
    "print(sigmoid(0))\n",
    "print(\"\\nSigmoid of 1:\")\n",
    "print(sigmoid(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent. CPU and GPU\n",
    "\n",
    "For the gradient descent, in order to process the large dataset, I will use a GPU approach using CuPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # get 'm', the number of rows in matrix x\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x,theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))    \n",
    "\n",
    "        # update the weights theta\n",
    "        theta = theta = theta - (alpha/m) * np.dot(x.transpose(),(h-y))\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "def gradientDescent_gpu(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # get 'm', the number of rows in matrix x\n",
    "    m = x.shape[0]\n",
    "\n",
    "    # Convert to cupy arrays\n",
    "    x = cp.array(x)\n",
    "    y = cp.array(y)\n",
    "    theta = cp.array(theta)\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(0, num_iters)):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = cp.dot(x,theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        h = cp.array(h)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        J = -1./m * (cp.dot(y.transpose(), cp.log(h)) + cp.dot((1-y).transpose(),cp.log(1-h)))\n",
    "\n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha/m) * cp.dot(x.transpose(),(h-y))\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    J = float(J)\n",
    "    theta = theta.get()\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Check the two functions\n",
    "np.random.seed(1)\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b46f4986664be990b505e45080571a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
     ]
    }
   ],
   "source": [
    "# Test the GPU version\n",
    "tmp_J, tmp_theta = gradientDescent_gpu(tmp_X, tmp_Y, cp.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_review(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:        \n",
    "        # increment the word count for the positive label 1\n",
    "        x[0,1] += freqs.get((word, 1.0),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word, 0.0),0)\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features of two phrases\n",
      "[[1.00e+00 1.75e+03 9.59e+02]]\n",
      "[[1.0000e+00 5.3690e+03 1.3958e+04]]\n"
     ]
    }
   ],
   "source": [
    "# Features of two random reviews\n",
    "print(\"\\nFeatures of two phrases\")\n",
    "print(extract_features(\"Ayer estuve genial\", freqs)) # a positive example\n",
    "print(extract_features(\"Hoy estamos muy mal\", freqs)) # a negative one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Here we will train the model using the training data, and the GPU version of the gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(train_x), 3))\n",
    "\n",
    "# Check if features.pkl exists\n",
    "if os.path.exists(\"features.pkl\"):\n",
    "    with open(\"features.pkl\", \"rb\") as f:\n",
    "        X = pickle.load(f)\n",
    "else:\n",
    "    for i in tqdm(range(len(train_x))):\n",
    "        X[i, :]= extract_features(train_x[i], freqs)\n",
    "    with open(\"features.pkl\", \"wb\") as f:\n",
    "        pickle.dump(X, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each train_y if == 1 then Y[i] = np.ones(1,1) else Y[i] = np.zeros(1,1)\n",
    "Y = np.zeros((len(train_y), 1))\n",
    "for i in range(len(train_y)):\n",
    "    if train_y[i] == 1:\n",
    "        Y[i, 0] = 1\n",
    "    else:\n",
    "        Y[i, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 elements of X and Y\n",
      "[[1.00000e+00 2.59999e+05 2.67971e+05]\n",
      " [1.00000e+00 1.95620e+05 2.00093e+05]\n",
      " [1.00000e+00 1.77269e+05 1.77734e+05]\n",
      " [1.00000e+00 4.56248e+05 4.96460e+05]\n",
      " [1.00000e+00 5.21486e+05 5.30807e+05]\n",
      " [1.00000e+00 2.48780e+05 2.59603e+05]\n",
      " [1.00000e+00 2.37611e+05 2.47525e+05]\n",
      " [1.00000e+00 2.20732e+05 2.44603e+05]\n",
      " [1.00000e+00 4.21248e+05 4.68492e+05]\n",
      " [1.00000e+00 9.73970e+04 1.00945e+05]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Print first 10 elements of X and Y\n",
    "print(\"\\nFirst 10 elements of X and Y\")\n",
    "print(X[:10, :])\n",
    "print(Y[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb10b0a015248b7b942277acc881e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient descent\n",
    "# Only use first 100 samples\n",
    "train_100 = X[:100, :]\n",
    "train_100_y = Y[:100, :]\n",
    "\n",
    "J_100, theta_100 = gradientDescent_gpu(train_100, train_100_y, np.zeros((3, 1)), 1e-8, 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The cost after training is nan\n",
      "The resulting vector of weights is [-1.4e-07, 0.00876147, -0.0081767]\n"
     ]
    }
   ],
   "source": [
    "# Print the cost and the resulting weight vector\n",
    "print(\"\\nThe cost after training is\", J_100)\n",
    "print(\"The resulting vector of weights is\", [round(t, 8) for t in np.squeeze(theta_100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936d3997c5014170b131eead9f9cdac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train with the entire dataset\n",
    "J_all, theta_all = gradientDescent_gpu(X, Y, np.zeros((3, 1)), 1e-9, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The cost after training is nan\n",
      "The resulting vector of weights is [1.2e-07, 0.00146131, -0.00129507]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe cost after training is\", J_all)\n",
    "print(\"The resulting vector of weights is\", [round(t, 8) for t in np.squeeze(theta_all)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is something wrong with the training data, because we get a division by zero error.\n",
    "We solved that using the Cuda approach, and getting the weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, freqs, theta):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - Text: a list of words\n",
    "        - freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        - theta: the weight vector of dimension (3,1)\n",
    "    Output:\n",
    "        - prediction: a float between 0 and 1\n",
    "    \"\"\"\n",
    "    # Get the feature vector\n",
    "    x = extract_features(text, freqs)\n",
    "    # Get the dot product of the feature vector and the weight vector\n",
    "    z = np.dot(x, theta)\n",
    "    # Get the sigmoid of the dot product\n",
    "    h = sigmoid(z)\n",
    "    # Return the prediction\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lo siento sixto tienes media de 4 en calculo los ultimos 5 a√±os y solo un 30% aprueba la asignatura milagros no hago -> [[0.85275035]]\n",
      "\n",
      " finde qe me voy fuera de malaga finde qe me salen 129391239 planes odio esta vida -> [[0.98856361]]\n",
      "\n",
      " malisima idea tomarme dos jarras antes de ponerme a estudiar -> [[0.79547013]]\n",
      "\n",
      " si jason statham fuera malague√±o y se qemase https://t.co/u9aaOvGulB -> [[0.53451258]]\n",
      "\n",
      " @warisntover https://t.co/Azy6SF7Yl5 https://t.co/nozgbtN2je -> [[0.50000003]]\n"
     ]
    }
   ],
   "source": [
    "# Predict 5 random tweets from tweets_text\n",
    "# Use 5 random indexes\n",
    "# tweets text is tweets.full_text from the tweets list\n",
    "tweets_text = [tweet.full_text for tweet in tweets]\n",
    "random_indexes = np.random.choice(len(tweets_text), 5, replace=False)\n",
    "for i in random_indexes:\n",
    "    # Print the quoted tweet -> prediction\n",
    "    print(\"\\n\", tweets_text[i], \"->\", predict_text(tweets_text[i], freqs, theta_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with column tweets_text and column prediction\n",
    "predictions = pd.DataFrame(columns=[\"tweets_text\", \"prediction\"])\n",
    "predictions[\"tweets_text\"] = tweets_text\n",
    "predictions_list = []\n",
    "for i in range(len(tweets_text)):\n",
    "    predictions_list.append(predict_text(tweets_text[i], freqs, theta_all))\n",
    "\n",
    "predictions[\"prediction\"] = predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count the preditions with > 0.5 and < 0.5\n",
    "pos_preds = [pred for pred in predictions[\"prediction\"] if pred > 0.5]\n",
    "neg_preds = [pred for pred in predictions[\"prediction\"] if pred < 0.5]\n",
    "\n",
    "# Bar plot of the number of positive and negative predictions\n",
    "plt.bar([\"Positive\", \"Negative\"], [len(pos_preds), len(neg_preds)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create df_bins. Columns predictions, and column bins (0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)\n",
    "df_bins = pd.DataFrame(columns=[\"predictions\", \"bins\"])\n",
    "df_bins[\"predictions\"] = predictions[\"prediction\"]\n",
    "df_bins[\"bins\"] = pd.cut(df_bins[\"predictions\"], bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "# Bins to strings\n",
    "df_bins[\"bins\"] = df_bins[\"bins\"].astype(str)\n",
    "\n",
    "# Group by bins and count the number of predictions\n",
    "df_bins_count = df_bins.groupby(\"bins\").count()\n",
    "\n",
    "# Plot size 10x10 figure\n",
    "plt.figure(figsize=(10, 7.5))\n",
    "# Plot the number of predictions in each bin\n",
    "# Bar color goes from red to green depending on the bin\n",
    "plt.bar(df_bins_count.index, df_bins_count[\"predictions\"])\n",
    "# x 30 degrees\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 5 predictions with the highest prediction\n",
      "                                            tweets_text  \\\n",
      "1236  Here‚Äôs a song for you‚Ä¶ I Met Sarah in the Bath...   \n",
      "276   increible como todos los tios de mi instituto ...   \n",
      "1145  los de mi trabajo tienen q conocer ya el 80% d...   \n",
      "629   the violent urge to comprarme unos chocoboms b...   \n",
      "607   me gusta qe en una empresa haya buen rollo y d...   \n",
      "\n",
      "                  prediction  \n",
      "1236  [[0.9999999610945769]]  \n",
      "276   [[0.9999999336545007]]  \n",
      "1145  [[0.9999996636671279]]  \n",
      "629   [[0.9999994491262499]]  \n",
      "607     [[0.99999915791048]]  \n",
      "\n",
      "The 5 predictions with the lowest prediction\n",
      "                                            tweets_text  \\\n",
      "1882  el truco esta en no esperarse nada nunca solo ...   \n",
      "1507  ojala fumar solo pa completar el desayuno ener...   \n",
      "202   otro post de ig que intenta hacerme sentir mal...   \n",
      "1501  menos mal qe es tele trabajo si no me tendria ...   \n",
      "69       como de mala idea es ir al gym dsps del buffet   \n",
      "\n",
      "                      prediction  \n",
      "1882  [[3.4613227674111666e-11]]  \n",
      "1507   [[4.169313309085718e-07]]  \n",
      "202    [[6.723874485507967e-07]]  \n",
      "1501   [[2.385061604805843e-06]]  \n",
      "69     [[3.091069118078556e-06]]  \n"
     ]
    }
   ],
   "source": [
    "# Print the 5 predictions with the highest prediction\n",
    "print(\"\\nThe 5 predictions with the highest prediction\")\n",
    "print(predictions.sort_values(by=\"prediction\", ascending=False).head(5))\n",
    "\n",
    "# Print the 5 predictions with the lowest prediction\n",
    "print(\"\\nThe 5 predictions with the lowest prediction\")\n",
    "print(predictions.sort_values(by=\"prediction\", ascending=True).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"\n",
    "        \n",
    "    # the list for storing predictions\n",
    "    y_hat = []\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_text(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0)\n",
    "\n",
    "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
    "    accuracy = (y_hat==np.squeeze(test_y)).sum()/len(test_x)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.6011\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta_all)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.6. This might be caused by a bad translated dataset. If we inspect the dataset, we see incoherent translations, and words that do not exist in the spanish alphabet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84be8c82a7a3e86db451810d88cd8e67624a6eca0a3f1ff4d59d995ee7a917f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
