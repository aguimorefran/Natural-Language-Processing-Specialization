{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 1: Classification and Vector Spaces\n",
    "# Week 1: Logistic Regression for Sentiment Analysis of Tweets\n",
    "## Own project: Analyzing the sentiment of my own tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download my own tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run assignment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Twitter credentials\n",
    "api_keys = json.load(open('twitter-api-keys.local.json'))\n",
    "bearer_token = api_keys[\"bearer_token\"]\n",
    "client = tweepy.Client(\n",
    "    bearer_token=api_keys['bearer_token'], wait_on_rate_limit=True)\n",
    "\n",
    "auth = tweepy.OAuthHandler(\n",
    "    consumer_key=api_keys['api_key'],\n",
    "    consumer_secret=api_keys['api_key_secret'],\n",
    "    access_token=api_keys['access_token'],\n",
    "    access_token_secret=api_keys['access_token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = \"fcx_xm\"\n",
    "tweets = api.user_timeline(screen_name=me, count=1000)\n",
    "tweet_text = [tweet.text for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating preprocessing functions for Spanish tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String cleaning function\n",
    "def clean_string(string):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - string: a string to be cleaned\n",
    "    Output:\n",
    "        - cleaned_string: a clean string with the following actions:\n",
    "            - lowercase\n",
    "            - remove punctuation\n",
    "            - remove URLs, hashtags, mentions\n",
    "    \"\"\"\n",
    "    string = re.sub(r'http\\S+', '', string)\n",
    "    string = re.sub(r'RT', '', string)\n",
    "    string = re.sub(r'@\\S+', '', string)\n",
    "    string = re.sub(r'#', '', string)\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    string = string.lower()\n",
    "    string = unidecode.unidecode(string)\n",
    "\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function\n",
    "def tokenize(string):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - string: a string to be tokenized\n",
    "    Output:\n",
    "        - tokens: a list of tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(string)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spanish stopwords function\n",
    "def remove_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - tokens: a list of tokens\n",
    "    Output:\n",
    "        - tokens: a list of tokens without stopwords\n",
    "    \"\"\"\n",
    "    stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem function for spanish\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - tokens: a list of tokens\n",
    "    Output:\n",
    "        - tokens: a list of stems\n",
    "    \"\"\"\n",
    "    stems = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "hoy le he cambiado el filtro de la cabina al coche porque traia el original de hace 10 años xd https://t.co/TlSnID72OE\n",
      "Cleaned text:\n",
      "hoy le he cambiado el filtro de la cabina al coche porque traia el original de hace 10 anos xd \n",
      "Tokenized text:\n",
      "['hoy', 'le', 'he', 'cambiado', 'el', 'filtro', 'de', 'la', 'cabina', 'al', 'coche', 'porque', 'traia', 'el', 'original', 'de', 'hace', '10', 'anos', 'xd']\n",
      "Removed stopwords:\n",
      "['hoy', 'cambiado', 'filtro', 'cabina', 'coche', 'traia', 'original', 'hace', '10', 'anos', 'xd']\n",
      "Stemmed text:\n",
      "['hoy', 'cambi', 'filtr', 'cabin', 'coch', 'trai', 'original', 'hac', '10', 'anos', 'xd']\n"
     ]
    }
   ],
   "source": [
    "# Show transformation progress\n",
    "print('Original text:')\n",
    "print(tweet_text[0])\n",
    "print('Cleaned text:')\n",
    "print(clean_string(tweet_text[0]))\n",
    "print('Tokenized text:')\n",
    "print(tokenize(clean_string(tweet_text[0])))\n",
    "print('Removed stopwords:')\n",
    "print(remove_stopwords(tokenize(clean_string(tweet_text[0]))))\n",
    "print('Stemmed text:')\n",
    "print(stem(remove_stopwords(tokenize(clean_string(tweet_text[0])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire process of the string\n",
    "def process_text(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - tweet: a string to be processed\n",
    "    Output:\n",
    "        - tokens: a list of tokens\n",
    "    \"\"\"\n",
    "    tweet = clean_string(tweet)\n",
    "    tokens = tokenize(tweet)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = stem(tokens)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hoy', 'cambi', 'filtr', 'cabin', 'coch', 'trai', 'original', 'hac', '10', 'anos', 'xd'], ['da'], ['vist', 'llev'], ['myth', 'we', 'dont', 'hav', 'solution', 'to', 'nuclears', 'wast', 'problem', 'reality', 'nucl', 'wast', 'isnt', 'problem', 'in', 'fact', 'its', 'the', 'best'], ['mir', 'contraluz']]\n"
     ]
    }
   ],
   "source": [
    "# Processed tweets\n",
    "processed_tweets = [process_text(tweet) for tweet in tweet_text]\n",
    "print(processed_tweets[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data for spanish positivity and negativity\n",
    "\n",
    "I will be using a dataset of positive and negative texts.\n",
    "\n",
    "URL: https://www.kaggle.com/datasets/luisdiegofv97/imdb-dataset-of-50k-movie-reviews-spanish?select=IMDB+Dataset+SPANISH.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_es  sentimiento\n",
       "0  Uno de los otros críticos ha mencionado que de...            1\n",
       "1  Una pequeña pequeña producción.La técnica de f...            1\n",
       "2  Pensé que esta era una manera maravillosa de p...            1\n",
       "3  Básicamente, hay una familia donde un niño peq...            0\n",
       "4  El \"amor en el tiempo\" de Petter Mattei es una...            1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the imdb_dataset.csv\n",
    "# Keep columns review_es, sentimiento. In sentimiento, replace \"positivo\" with 1 and \"negativo\" with 0\n",
    "data = pandas.read_csv('imdb_dataset.csv')\n",
    "data = data[['review_es', 'sentimiento']]\n",
    "data.sentimiento = data.sentimiento.replace(['positivo', 'negativo'], [1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data in a new csv file\n",
    "data.to_csv('imdb_dataset_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           review_es  sentimiento\n",
      "0  Uno de los otros críticos ha mencionado que de...            1\n",
      "1  Una pequeña pequeña producción.La técnica de f...            1\n",
      "2  Pensé que esta era una manera maravillosa de p...            1\n",
      "3  Básicamente, hay una familia donde un niño peq...            0\n",
      "4  El \"amor en el tiempo\" de Petter Mattei es una...            1\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Create x and y lists\n",
    "x = data.review_es\n",
    "y = data.sentimiento\n",
    "\n",
    "# Print head 5 and len of both\n",
    "print(data.head(5))\n",
    "print(len(x))\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency distribution of the words in the reviews\n",
    "\n",
    "def build_freqs(train_x, train_y):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - train_x: the list of reviews\n",
    "        - train_y: the list of labels\n",
    "    Output:\n",
    "        - freqs: a dictionary with the frequency of each word in the reviews\n",
    "\n",
    "    Dictionary structure:\n",
    "    {\n",
    "        'word1': {\n",
    "            'positive': int,\n",
    "            'negative': int\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Iterate thru the length of the array\n",
    "    # Tokenize each review in train x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = build_freqs(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pelicul', {'positive': 0, 'negative': 173675}), ('mas', {'positive': 0, 'negative': 57849}), ('the', {'positive': 0, 'negative': 53699}), ('si', {'positive': 0, 'negative': 40682}), ('hac', {'positive': 0, 'negative': 38019}), ('pued', {'positive': 0, 'negative': 35100}), ('sol', {'positive': 0, 'negative': 31429}), ('buen', {'positive': 0, 'negative': 30886}), ('ser', {'positive': 0, 'negative': 28230}), ('histori', {'positive': 0, 'negative': 27579})]\n"
     ]
    }
   ],
   "source": [
    "# Show sorted list of words and their frequencies\n",
    "print(sorted(freqs.items(), key=lambda x: x[1]['positive'] + x[1]['negative'], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets\n",
    "train_x = x[:int(len(x) * 0.8)]\n",
    "train_y = y[:int(len(y) * 0.8)]\n",
    "test_x = x[int(len(x) * 0.8):]\n",
    "test_y = y[int(len(y) * 0.8):]\n",
    "\n",
    "# Print len of all\n",
    "print(len(train_x))\n",
    "print(len(train_y))\n",
    "print(len(test_x))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid, gradient descent, feature extraction, and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - x: a number\n",
    "    Output:\n",
    "        - sigmoid: the sigmoid of x\n",
    "    \"\"\"\n",
    "    sigmoid = 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "def gradient_descent(x, y, theta, alpha, iterations):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    '''\n",
    "    m = x.shape[0]\n",
    "    J_history = []\n",
    "    for i in range(iterations):\n",
    "        z = np.dot(x, theta)\n",
    "        h = sigmoid(z)\n",
    "        J = -1./m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(),np.log(1-h)))  \n",
    "        J_history.append(J)\n",
    "        theta = theta - (alpha/m) * np.dot(x.transpose(), (h-y))\n",
    "    J = float(J)\n",
    "    return J_history, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def feature_extraction(text, freqs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - word: a text\n",
    "        - freqs: a dictionary with the frequency of each word in the reviews\n",
    "    Output:\n",
    "        - features: an array of (1, 3) with the following features:\n",
    "            - 1 = 1\n",
    "            - 2 = frequency of the tokens in the positive reviews\n",
    "            - 3 = frequency of the tokens in the negative reviews\n",
    "    \"\"\"\n",
    "    features = np.zeros((1, 3))\n",
    "    features[0, 0] = 1\n",
    "    tokens = process_text(text)\n",
    "    for token in tokens:\n",
    "        features[0][1] += freqs[token]['positive']\n",
    "        features[0][2] += freqs[token]['negative']\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction with 5 random reviews:\n",
      "Review: Vi a Marigold en una vista previa que se muestra hace unos días, y encontré que era una película completamente absorbente y agradable. La película se trata de una actriz estadounidense no tan exitosa que va a la India para que actúe en una película de bajo presupuesto, solo para encontrarse trenzada allí cuando se encuentra a la llegada de que la financiación de la película ha desaparecido, junto con los productores e inversores. Un encuentro casual con una película india que disparara a la cercana la lleva a ser contratada por un pequeño papel de bailarina en eso. Dado que las películas indias incorporan una cantidad significativa de cantar y bailes, este es un problema para que Marigold, que tiene dos pies izquierdos, por no mencionar una personalidad tan estrechamente enrollada y espinosa que apenas puede escuchar la música, y mucho menos sentirlo, y mucho menos. Como Prem, el coreógrafo de la película, le ofrece a ella. Pero la palabra \"Prem\", la Palabra, no la persona, significa \"amor\", y Prem, la persona, no la palabra, parece encarnar esa emoción. En la forma en que se ocupa de todo lo que a su alrededor, ya sean sus amigos de producción que introdujeran a Marigold al rodaje, los cables narcisistas y arrogantes de la película, o la propia caléndula y perra. Pronto, bajo su tutela experta y un trato entrañable, Marigold encuentra sus pies, literalmente y figuradamente. Debe decir una palabra para aquellos que no están familiarizados con el uso de la canción y la danza en las películas indias. A diferencia de los musicales estadounidenses, la historia avanza a través de estos números de baile, ya que se desarrollan los desarrollos de la trama, y ​​las transformaciones de caracteres se producen en paralelo con el baile. También debe señalarse que la danza india es mucho más que un mero movimiento. Una parte esencial de ello es la promulgación de los sentimientos y las emociones del bailarín mientras contaba la historia de la danza. Este es el propósito principal de la danza y el bailarín. Que se demuestra que la etapa de los logros se encuentra en una impresionante número de baile a través de A Midway, cuando se encuentra en Marigold, mientras realiza el baile que está obligado a hacer por la película dentro de la Película, también expresa su amor por su prem. Es una actuación increíble de Ali Larter, especialmente cuando se considera que no está acostumbrada a bailar en sus películas, o emotir los sentimientos de su personaje a través de la danza. Muestra su habilidad como actriz, así como cuánto trabajo duro ha puesto en el rol. Por supuesto, ninguna película romántica puede trabajar sin un príncipe creíble encantador. Salman Khan, quien juega el papel de Premp, se ajusta al papel a un T. Incluso cuando resulta que es un príncipe no tan encantador, no pierde la simpatía de la audiencia. Salman ha estado gobernando el cine hindi (a veces llamado Bollywood) durante muchos años, y vale la pena recordar que su primer papel principal también fue como prem. Es completamente encantador, dulce, adorable, sexy y vulnerable. ¡Para aquellos que nunca lo han encontrado en la pantalla antes, estén preparados para ser golpeados con mega dosis de magnetismo puro! Él y Ali Larter hacen una pareja encantadora, y también se adaptan a su actuación como en su apariencia. ¡Se las arreglarán para resolver sus problemas? No parece posible, ya que escuchamos la última canción de la película, una hermosa mezcla de hecho y fantasía, realidad y metáfora. El final sin duda tomaron parte de la audiencia, lo vi por sorpresa, pero se quedaron satisfechos. Las canciones se utilizan muy inteligentemente. Están en hindi, no sustituidos, para las secuencias de cine dentro de la película, y en inglés para otras ocasiones. Pero su significado siempre está claro del contexto y la coreografía. La comedia romántica es una comedia romántica muy satisfactoria, sí, también hay un poco de humor en él. Las ubicaciones y disfraces indios le dan una calidad de cuento de hadas, que se adaptan a una historia que se puede comparar con un cuento de hadas moderno. Si eres o ha sido curioso por el cine indio, pero no dudó de probarlo, esta es una excelente introducción. Captura el color y la vitalidad de las películas indias, no solo en los disfraces y joyas (que son bastante impresionantes), sino también en los bailes animados y la música de sonido mundial. Si eres fanático de Ali Larter, deberías verlo por ella. Excelente actuación para retratar a una mujer egoísta, exigente, \"de alta mantenimiento\" que, sin embargo, tiene una atracción interna que inspira el amor de dos hombres. Si eres una niña, disfrutará admirando los encantadores disfraces de Ali y oglando su hunk de un hombre líder. Si eres un chico, no solo puedes admirar a Ali en sus trajes sexy, sino que aprende de Salman Khan lo que se necesita para sacar al corazón amoroso, incluso de alguien tan nervioso como Marigold.\n",
      "Features: [[1.000000e+00 0.000000e+00 5.181716e+06]]\n",
      "Review: Recientemente vio esta atrocidad en mi programa de cine, y pensé que era horrible, como dije en mi lema, era pretencioso, trillado, mezquino y fenomenalmente autoidental. Me considero un fanático de la película, y todas las cosas queLa película tiene para ofrecer.Si quiero ver un documental en el Festival de Cannes, veré A & E .... Y probablemente serían mucho más objetivos al respecto. No lo recomiendo, el período.\n",
      "Features: [[1.0000e+00 0.0000e+00 5.6127e+05]]\n",
      "Review: Esto debe ir acompañado de una calificación especial y advertencia: no se recomienda a las personas normales. La obsesión de Daneliuc con las funciones corporales más sucias se convierte aquí en una pesadilla real.Además, es evidente que el hombre es un misántropo, odia a todos, su país, su pueblo, sus actores, su trabajo.Y este odio lo hace ciego y se olvida de la profesión que conocía hace mucho tiempo. Esta llamada \"película\" es solo una horrible cadena de imágenes repugnantes, sin valor artístico ni conocimientos profesionales.Es un insulto al buen gusto y al buen sentido.Vergüenza, vergüenza, vergüenza!\n",
      "Features: [[1.00000e+00 0.00000e+00 5.62612e+05]]\n",
      "Review: Una gran película que requiere un gusto adquirido.Si estás en acción, las películas de Wham Bam y odian las historias de amor graves, entonces no es para ti.De lo contrario, si te gusta sentarte frente a una buena película inteligente de vez en cuando, y otra vez recomiendo esto muy altamente.Fácilmente la mejor película producida en Bollywood este siglo. La única otra película india que daría 10/10 por es Dil Wale Dulhaniya Le Jayenge.Incluso entonces se presenta en segundo lugar a esta obra maestra.\n",
      "Features: [[1.000000e+00 0.000000e+00 1.146812e+06]]\n",
      "Review: Esta es una película muy difícil, y es casi imposible hacer un manejo de lo que está pasando.Al principio, parece ser una película más bien peatonal sobre un chico (Trelkovsky) que necesita un apartamento y, bastante, de manera cresidenta, cuando el inquilino actual (una mujer) se suicida.Luego los giros y vueltas comienzan.¿Están los vecinos tratando de matarlo?¿Y por qué la ropa del inquilino muerto se vuelve en el apartamento?Uno se pregunta, finalmente, si trelkovksy _is_ el inquilino anterior.Spoiler Spoiler Spoiler Spoiler Spoiler Spoiler Uno de los trucos Polanski Los tirones en nosotros es mentirnos.Asumimos cuándo vemos las cosas desde el punto de vista de un personaje que vemos las cosas como lo hace el personaje y que puede haber distorsiones de la realidad.Suponimos que cuando la cámara nos está mostrando cosas desde su punto de vista omnisciente que vemos la actualidad, pero Polanski nos tiene la cámara.\n",
      "Features: [[1.00000e+00 0.00000e+00 8.94665e+05]]\n"
     ]
    }
   ],
   "source": [
    "# Test feature extraction with 5 random reviews\n",
    "print('Feature extraction with 5 random reviews:')\n",
    "idx = np.random.randint(0, len(x), 5)\n",
    "for i in idx:\n",
    "    print(\"Review:\", x[i])\n",
    "    # Print in scientific notation\n",
    "    print(\"Features:\", feature_extraction(x[i], freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.7310585786300049\n",
      "Cost: [[0.58333801]]\n",
      "Theta: [[-0.63180767]\n",
      " [-0.15851034]\n",
      " [ 0.49948201]]\n"
     ]
    }
   ],
   "source": [
    "# Test sigmoid and gradient\n",
    "print(sigmoid(0))\n",
    "print(sigmoid(1))\n",
    "\n",
    "tmp_x = np.append(np.ones((10, 1)), np.random.randn(10, 2), axis=1)\n",
    "tmp_x\n",
    "tmp_y = (np.random.randn(10, 1) > 0.35).astype(float)\n",
    "tmp_y\n",
    "\n",
    "tmp_J, tmp_theta = gradient_descent(tmp_x, tmp_y, np.zeros((3, 1)), 0.01, 1000)\n",
    "print(\"Cost:\", tmp_J[-1]) \n",
    "print(\"Theta:\", tmp_theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84be8c82a7a3e86db451810d88cd8e67624a6eca0a3f1ff4d59d995ee7a917f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
